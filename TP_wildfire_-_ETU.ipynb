{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# If only the Notebook file has been downloaded from the github repos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EkEAJwKpWJ5R"
      },
      "source": [
        "Mount your Drive to Colab, \n",
        "Clone the github TP, \n",
        "Go in the github directory, \n",
        "Download and extract the Dataset (localy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqtwKTMIM7gq",
        "outputId": "80f863f3-32fa-4862-be32-dcfab9d7421c"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB == True:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "\n",
        "    %cd /content/gdrive/MyDrive\n",
        "\n",
        "    # if wildfire_segmentation folder doesn't exist then clone the github project in /content/gdrive/MyDrive\n",
        "    ! [ ! -d Wildfire_segmentation ] && git clone \"https://github.com/ThomasLOUIS1/Wildfire_segmentation.git\"\n",
        "\n",
        "    # Go to the github project folder\n",
        "    %cd Wildfire_segmentation/data\n",
        "\n",
        "    # if dataset.zip dosn't exist then download it\n",
        "    ! [ ! -f dataset.zip ] && echo \"dataset.zip dosn't exist\" && wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1idUH24mGyAegB0YzDcJmd9XyNVbqGsnS' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1idUH24mGyAegB0YzDcJmd9XyNVbqGsnS\" -O dataset.zip && rm -rf /tmp/cookies.txt\n",
        "\n",
        "    # if sample_data/RGB dosn't exist then exctract the dataset into sample_data/\n",
        "    ! [ ! -d /content/sample_data/RGB ] && echo \"data dosn't exist\" && unzip -qq dataset.zip -d /content/sample_data\n",
        "\n",
        "    data_dir = \"/content/sample_data\"\n",
        "\n",
        "    %cd /content/gdrive/MyDrive/Wildfire_segmentation\n",
        "else : \n",
        "    # if dataset.zip dosn't exist then download it\n",
        "    ! [ ! -f data/dataset.zip ] && echo \"dataset.zip doesn't exist\" && wget -P data/ --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1idUH24mGyAegB0YzDcJmd9XyNVbqGsnS' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1idUH24mGyAegB0YzDcJmd9XyNVbqGsnS\" -O dataset.zip && rm -rf /tmp/cookies.txt\n",
        "    \n",
        "    # if data/RGB dosn't exist then exctract the dataset into data/\n",
        "    ! [ ! -d data/RGB ] && echo \"data doesn't exist\" && unzip -qq data/dataset.zip -d data/\n",
        "\n",
        "    data_dir = \"data/\"\n",
        "\n",
        "    import os\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wildfire Segmentation with Multi-spectral Images"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What are multi-spectrale Images and why using it for Wildfire Segmentation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi-spectral images can be used for wildfire segmentation because they capture information about the target in multiple wavelength bands, which can provide more information about the characteristics of the wildfire and the surrounding area. \n",
        "\n",
        "For example, near-infrared (NIR) bands can be used to identify vegetation, while shortwave infrared (SWIR) bands can be used to detect the presence of smoke. Additionally, using multiple wavelength bands can help to reduce the impact of atmospheric conditions, such as clouds and haze, on the image. This can improve the accuracy of the segmentation and make it easier to identify the wildfire in the image.\n",
        "\n",
        "These images are stored in .tif files. .tif (TIFF) is a widely-used file format for images. It is capable of storing images in a lossless format, meaning that no data is lost when the image is compressed. This makes it a popular choice for storing high-quality images, such as those used in professional photography, printing or satellite imagery. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6LLEE9GnWYAG"
      },
      "source": [
        "# 0.1 Get dataset files paths"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading a segmentation dataset differ from loading a classification dataset with a tensorflow or Keras function.\n",
        "\n",
        "You don't load images from classes, you load images not bellonging to any classes and masks/targets that contains one or more classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moaMvd0uQRWW",
        "outputId": "b25f099c-9080-4d41-e9df-ab82a71d3667"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "# Dataset folder paths declaration\n",
        "RGB_dir = data_dir + \"/______\"                    # Only for display purpose\n",
        "triband_dir = data_dir + \"/______\"    # Data directory\n",
        "target_dir = data_dir + \"/______\"          # Labels directory\n",
        "\n",
        "# Define images size\n",
        "img_size = (______, ______)\n",
        "\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "######################################\n",
        "# What's the purpose of the following function ?\n",
        "# Answer : ___________________________________.\n",
        "def sort_tif_paths_from_folder(dir):\n",
        "    \"\"\"\n",
        "    Get all tif files sorted by name in a directory and return as a sorted list.\n",
        "    \n",
        "    Parameters:\n",
        "    dir (str): directory path containing the tif files\n",
        "\n",
        "    Returns:\n",
        "    list: sorted list of tif file paths in the directory\n",
        "    \"\"\"\n",
        "    paths_list = sorted(\n",
        "    [\n",
        "        os.path.join(dir, fname)\n",
        "        for fname in os.listdir(dir)\n",
        "        if fname.endswith(\".tif\")\n",
        "    ]\n",
        "    )\n",
        "    return paths_list\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "# Get sorted list of tif files for RGB images\n",
        "RGB_img_paths = sort_tif_paths_from_folder(RGB_dir)\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "# Get sorted list of tif files for triband training images\n",
        "triband_img_paths_train = sort_tif_paths_from_folder(triband_dir + \"/______\" )\n",
        "# Get sorted list of tif files for triband validation images\n",
        "triband_img_paths_val = sort_tif_paths_from_folder(triband_dir + \"/______\")\n",
        "# Get sorted list of tif files for triband test images\n",
        "triband_img_paths_test = sort_tif_paths_from_folder(triband_dir + \"/______\")\n",
        "\n",
        "# Get sorted list of tif files for target training images\n",
        "mask_img_paths_train = sort_tif_paths_from_folder(target_dir + \"/______\")\n",
        "# Get sorted list of tif files for target validation images\n",
        "mask_img_paths_val = sort_tif_paths_from_folder(target_dir + \"/______\")\n",
        "# Get sorted list of tif files for target test images\n",
        "mask_img_paths_test = sort_tif_paths_from_folder(target_dir + \"/______\")\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "# The idea is to compute the number of samples we have. \n",
        "# Tips : you have to sum the length of triband_img_paths_train, triband_img_paths_val and triband_img_paths_test arrays\n",
        "######################################\n",
        "print(\"Number of samples from {} : {}\".format(triband_dir, ______))\n",
        "print(\"Number of samples from {} : {}\".format(target_dir, ______)\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "# Print 6 firsts paths from RGB, biband and target paths\n",
        "# Note: Only works for the first 15 because we don't have many RGB images\n",
        "for RGB_path, triband_path, target_path in zip(RGB_img_paths[:6], triband_img_paths_train[:6], mask_img_paths_train[:6]):\n",
        "    print(RGB_path, \"|\", triband_path, \"|\", target_path)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0d6ESBhIX8u3"
      },
      "source": [
        "# 0.2 Visualize RGB / Tri-bands / mask datas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SU9SFiLwc77e"
      },
      "source": [
        "First we import a function to display several images (declared in /utils.py) and others utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTUwJNd8b4M5"
      },
      "outputs": [],
      "source": [
        "# Display 1 or more numpy matrix \n",
        "from utils import display_matrix\n",
        "\n",
        "# Used to load/Read/ and plot images \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Used to perform manipulation on matrix/images\n",
        "import numpy as np\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Visualization "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EiFO_Pj5dNv-"
      },
      "source": [
        "We visualize the RBG image, the tri-bands image and the true ground mask.\n",
        "\n",
        "You will see that with the RGB image, it's very difficult to see the fire... But with the tri-bands image, it's quite easy !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HjOFgzqCYC39",
        "outputId": "a51ab9d1-8270-4492-a5d1-8ae7dcd31e4e"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "n_images_to_display = 3\n",
        "for id in range(len(RGB_img_paths)):\n",
        "    # Read the mask data for the current iteration\n",
        "    image_masks = Image.open(mask_img_paths_train[id])\n",
        "    # Check if there's at least one \"Fire\" pixel and if the number of images displayed is less than 3\n",
        "\n",
        "    if np.max(image_masks) > 0 and i < n_images_to_display:\n",
        "        # Read RGB and Tri-bands data\n",
        "        image_RGB = Image.open(RGB_img_paths[id])\n",
        "        image_triband = Image.open(triband_img_paths_train[id])\n",
        "\n",
        "        # print id and path of the associated RGB path\n",
        "        print(\"Image n {}, path : {}\".format(id, RGB_img_paths[id]))\n",
        "        \n",
        "        # Store data in matrix and display it\n",
        "        matrix = [[image_RGB, image_triband, image_masks]]\n",
        "        display_matrix(matrix, title_list=[\"RGB\", \"Tri-Bands\", \"Ground Truth Mask\"])\n",
        "        \n",
        "        # Increment counter for number of images displayed\n",
        "        i += 1\n",
        "\n",
        "    # Break out of loop if 3 images have been displayed\n",
        "    if i == n_images_to_display:\n",
        "        break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">What do you think of Tribands images compared to RGB images ?</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pbbQWurXXJCN"
      },
      "source": [
        "# 0.3 Load dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now load the dataset to use it later for training.\n",
        "\n",
        "First we define a function to create a dataset from paths gathered previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "def load_triband_and_target_from_paths(paths = None):\n",
        "    \"\"\"\n",
        "    Load the tri-bands and target images data from the given paths and convert them into a tensorflow dataset.\n",
        "    \n",
        "    Parameters:\n",
        "    paths (List): List of tuples of tri-bands and target image paths\n",
        "    \n",
        "    Returns:\n",
        "    data (tf.data.Dataset): A tensorflow dataset object with tri-bands and target images data.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize arrays to store tri-bands image data and target image data\n",
        "    x = np.zeros((len(paths),) + img_size + (3,), dtype=\"float32\")\n",
        "    y = np.zeros((len(paths),) + img_size + (1,), dtype=\"float32\")\n",
        "    \n",
        "    # Loop through the list of tri-bands and target image paths\n",
        "    for i, (triband_path, mask_path)  in enumerate(paths):\n",
        "        \n",
        "        # Read the tri-bands image file and normalize the data\n",
        "        triband = np.array(Image.open(______)) / ______\n",
        "        x[i] = triband\n",
        "        \n",
        "        # Open the target image file\n",
        "        mask = np.array(Image.open(______))\n",
        "        # Add an extra dimension to the target data for compatibility with the model\n",
        "        mask = np.expand_dims(mask, 2)\n",
        "        y[i] = mask\n",
        "        \n",
        "    # Create a tensorflow dataset from tri-bands and target image data\n",
        "    data = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    \n",
        "    # Batch the dataset and fetch the data in advance for faster processing\n",
        "    data = data.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    return data\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we use it to load train, val and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tuples of (Tri-bands image path, Target image path) for train, val and test datasets\n",
        "train_paths = list(zip(triband_img_paths_train, mask_img_paths_train))\n",
        "val_paths = list(zip(triband_img_paths_val, mask_img_paths_val))\n",
        "test_paths = list(zip(triband_img_paths_test, mask_img_paths_test))\n",
        "\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "# Load train, val and test datasets from the tuple of Tri-bands and Target image paths\n",
        "train_ds =  load_triband_and_target_from_paths(______)\n",
        "val_ds = load_triband_and_target_from_paths(______)\n",
        "test_ds = load_triband_and_target_from_paths(______)\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.0 Build the model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will create a very classical Unet-like CNN model that we'll be used for each training."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">Create the Unet-like CNN model with the following architecture : </span>\n",
        "1. A 2D convolution with 8 filters of 3*3 and a ReLU activation \n",
        "2. A Max Pooling 2D with 2*2 kernel \n",
        "  ---\n",
        "3. A 2D convolution with 4 filters of 3*3 and a ReLU activation \n",
        "  ---\n",
        "4. A Dropout layer at 25%\n",
        "  ---\n",
        "5. A 2D Transpose Convolution with 4 filters of 3*3 and a ReLU activation \n",
        "6. A Up Sampling 2D with 2*2 kernel \n",
        "  ---\n",
        "7. A 2D Transpose Convolution with 8 filters of 3*3 and a ReLU activation \n",
        "8. A 2D Convolution with 1 filter of 3*3, a ReLU activation with a same padding\n",
        "\n",
        "At the end display the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the code with the architecture of the model described above : \n",
        "######################################\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(___________)\n",
        "\n",
        "...\n",
        "\n",
        "model.add(___________)\n",
        "\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kD9QgU1ueqHJ"
      },
      "source": [
        "# 1.1 Clone the 1st model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will copy the model into a new \"model1\". Doing that we allow us to start with the same model for each training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJId_sdsess9",
        "outputId": "2c553584-7e21-4a3c-fa89-0cb6a3ef691b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "model1 = clone_model(model)\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\"> Compile the model with the following parameters : </span>\n",
        " - An Adam optimizer with a learning rate at 0.01\n",
        " - A Binary Accuracy metrics\n",
        " - A Binary Crossentropy loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add Optimizer, Metric(s), Loss(es) and compile the model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "model1.compile(optimizer = ______, metrics = ______, loss = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmfpy02fWlf"
      },
      "source": [
        "# 1.2 Train the model1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will train the model1 for 4 epochs with \"train_ds\" dataset for trainong and \"val_ds\" for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caupMupdfDxU",
        "outputId": "8d3e90cd-fded-44fb-e46e-bf3c86265f56"
      },
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "history = model1.fit(______, epochs = ______, validation_data = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model1 with the test_ds dataset >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import a function that display scores and values (see utils.py)\n",
        "from utils import print_score\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "model1_score = ______.evaluate(______)\n",
        "\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "# Display model1 scores\n",
        "print_score(model1_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">What do you think of the model1 scores ?</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Is this score really accurate ?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check this with diplaying some prediction from the test set >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import a predict function similar to model.predict but with a treshhold at 0.5 (see utils.py)\n",
        "from utils import predict\n",
        "\n",
        "# A function that display firsts n_range tri-bands, masks and predictions\n",
        "def display_sample_prediction(model, triband_paths, mask_paths, n_range = 3): \n",
        "  i = 0\n",
        "  n_range = n_range\n",
        "\n",
        "  # Pass through len(RGB_img_paths) firsts images paths\n",
        "  for id in range(len(RGB_img_paths)):\n",
        "    # Read the mask data for the current iteration\n",
        "    image_masks = Image.open(mask_paths[id])\n",
        "    # Check if there's at least one \"Fire\" pixel and if the number of images displayed is less than n_range\n",
        "\n",
        "    if np.max(image_masks) > 0 and i < n_range:\n",
        "          \n",
        "      n_triband = np.array(Image.open(triband_paths[id]))/255.0\n",
        "      tribands = np.expand_dims(n_triband, 0)\n",
        "\n",
        "      # print id and path of the associated Tri-bands path\n",
        "      print(\"Image n {}, path : {}\".format(id, triband_paths[id]))\n",
        "      \n",
        "      predicted_mask = predict(model, tribands)\n",
        "      predicted_mask = np.squeeze(predicted_mask)\n",
        "\n",
        "      matrix=[[n_triband, image_masks, predicted_mask]] # [[Tribands,mask,predict]]\n",
        "\n",
        "      display_matrix(matrix ,title_list=['Tri-bands', 'GT Mask', 'Predicted'])\n",
        "      \n",
        "      # Increment counter for number of images displayed\n",
        "      i += 1\n",
        "    \n",
        "    # Break out of loop if n_range images have been displayed\n",
        "    if i == n_range:\n",
        "        break\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "# Diplay Tri-bands, mask and prediction of the model1\n",
        "display_sample_prediction(______, ______, ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">What do you think of the Predictions compared to the Masks ?</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The effect of an unbalanced dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The problem comes from the fact that there are more \"No_fire\" pixels than \"Fire\" pixels, much much more. \n",
        "\n",
        "Then the neural network don't find interesting to give importance to these pixels, then it will classify all pixels as \"No_fire\"... \n",
        "\n",
        "We can see it with a Confusion Matrix >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import display_confusion_matrix, load_masks\n",
        "\n",
        "test_gt_masks = load_masks(mask_img_paths_test, img_size=img_size)\n",
        "\n",
        "display_confusion_matrix(predict(model1, test_ds), test_gt_masks)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.3 Dataset balancing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are several ways to prevent bad generalization from an unbalanced dataset such as :\n",
        "\n",
        " - Resampling techniques such as oversampling the minority class or undersampling the majority class to balance the dataset.\n",
        "\n",
        " - Using a threshold in the model's decision function to adjust the trade-off between precision and recall.\n",
        "\n",
        " - Collecting more data to balance the classes or using a different dataset.\n",
        "\n",
        "But here the simpliest way for us is to use a weighted loss function to give more importance to the minority class during training.\n",
        "\n",
        "On the top of that we will use more metrics allowing us to see if the \"Fire\" class is properly classify."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kD9QgU1ueqHJ"
      },
      "source": [
        "# 2.1 Clone and train the 2nd model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will clone the same Unet-like CNN model but we will balance the dataset during training.\n",
        "\n",
        "To do so we will use a loss giving more \"weight\" to the \"Fire\" class as it is really rare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJId_sdsess9",
        "outputId": "2c553584-7e21-4a3c-fa89-0cb6a3ef691b"
      },
      "outputs": [],
      "source": [
        "\n",
        "model2 = clone_model(model)\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.2 Train with weighted loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This time we will use the weighted binary crossentropy loss defined bellow.\n",
        "\n",
        "But we need to choose the weight for each classes \"Fire\" and \"No_fire\", to do so we have 3 choices :\n",
        "\n",
        " - Try iteratively several weights ( Could be very long )\n",
        " - Use backprop to compute these parameters ( Could be difficult )\n",
        " - Compute the number of \"Fire\" pixels and \"No_Fire\" pixels to get a proportion of each pixels\n",
        "\n",
        " Here we will try to compute the number of \"Fire\" pixels and \"No_Fire\" pixels in our train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zeros = 0\n",
        "ones  = 0\n",
        "for x, y in train_ds:\n",
        "  zeros += np.count_nonzero(y == 0)\n",
        "  ones += np.count_nonzero(y == 1)\n",
        "\n",
        "ones_proportion = ones/(min(ones,zeros))\n",
        "zeros_proportion = zeros/(min(ones,zeros))\n",
        "\n",
        "ones_weight = zeros_proportion\n",
        "zeros_weight = ones_proportion\n",
        "\n",
        "print(\"Number of ones : {} | Number of zeros : {}\".format(ones, zeros))\n",
        "print(\"Ones proportion : {} | Zeros proportion : {}\".format(ones_proportion, zeros_proportion))\n",
        "print(\"Ones weight : {} | Zeros weight : {}\".format(ones_weight, zeros_weight))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These results means that for 1 \"Fire\" pixel, we have around 550 \"No_Fire\" pixels. Meaning our dataset is clearly unbalanced.\n",
        "\n",
        "We could use the proportion of \"No_Fire\" pixel (550) as a class weight for \"Fire\" class but this is a too big number to use it weighted binary crossentropy loss, in fact if we try this our model will not converge... One reason is if in one batch there is a too large amount of \"Fire\" pixels, the loss will \"explode\" and diverge. One way to prevent this could be too reduce the learning rate. \n",
        "\n",
        "In the case of strong unbalanced classes, the iterative way of founding the best class weight is mandatory.\n",
        "\n",
        "We will set this class weight to 26 as we tested some for the TP. In another notebook you will be able to try different class weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ones_weight = 26\n",
        "zeros_weight = 1.0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a custom loss function allowing to pu weight for each class :\n",
        "To do so, the idea is to declare a function **weighted_binary_crossentropy** that takes two inputs, **y_true** and **y_pred**, which represent the true label and the predicted label respectively. The **y_true** and **y_pred** are clipped to a small value close to 0 (K.epsilon()) to avoid numerical instability in the computation of logarithms. \n",
        "\n",
        "The loss is computed as the weighted negative log-likelihood of the true label, where the weight is determined by two variables ones_weight and zeros_weight. The loss is then averaged across all samples (axis=-1) and returned as the final result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def weighted_binary_crossentropy( y_true, y_pred):\n",
        "    # Clipping y_true and y_pred to avoid numeric instability\n",
        "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
        "\n",
        "    # Calculating the weighted negative log-likelihood loss\n",
        "    # The original logaritic loss is : loss = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
        "    loss = -(y_true * K.log(y_pred) * ones_weight + (1 - y_true) * K.log(1 - y_pred) * zeros_weight)\n",
        "\n",
        "    # Averaging the loss across all samples\n",
        "    return K.mean(loss, axis=-1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3 Adding more metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this training we need more than the Binary Accuracy metrics as it is not enough to see if the model converge.\n",
        "\n",
        "We will use 3 metrics :\n",
        " - Recall \n",
        " - Precision \n",
        " - F1-score \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\"> Give an explanation for each metrics :</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " - Recall is ...\n",
        "\n",
        " - Precision is ...\n",
        "\n",
        " - F1-score is ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\"> Compile model2 with the following parameters : </span>\n",
        " - An Adam optimizer with a learning rate at 0.01\n",
        " - The weighted binary crossentropy loss created above\n",
        " - Several metrics :\n",
        "   - Binary Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from metrics_and_losses import recall_m, precision_m, f1_m\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "metrics = [______, ______, ______, ______]\n",
        "\n",
        "______.compile(optimizer = ______, metrics = ______, loss = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmfpy02fWlf"
      },
      "source": [
        "# 2.4 Train model2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will train the model2 for 4 epochs with \"train_ds\" dataset for trainong and \"val_ds\" for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caupMupdfDxU",
        "outputId": "8d3e90cd-fded-44fb-e46e-bf3c86265f56"
      },
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "history = model2.fit(______, epochs = ______, validation_data = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model2 with the test_ds dataset >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "model2_score = ______.evaluate(______)\n",
        "\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "# Display model1 scores\n",
        "print_score(model2_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Better results ?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again we will see if the model works better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "# Diplay Tri-bands, mask and prediction of the model2\n",
        "display_sample_prediction(______, ______, ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">What do you think of the Predictions compared to the Masks ?</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can check again the Confusion Matrix >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import display_confusion_matrix, load_masks\n",
        "\n",
        "# test_gt_masks = load_masks(mask_img_paths_test) # already load\n",
        "\n",
        "display_confusion_matrix(predict(model2, test_ds), test_gt_masks)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's better, but can we improve the F1 score ?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kD9QgU1ueqHJ"
      },
      "source": [
        "# 3.1 clone and train the 3rd model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again we build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJId_sdsess9",
        "outputId": "2c553584-7e21-4a3c-fa89-0cb6a3ef691b"
      },
      "outputs": [],
      "source": [
        "model3 = clone_model(model)\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.2 Train with Dice/F1-score loss\n",
        "The Dice loss is a loss function commonly used in image segmentation tasks. It is a variation of the Sørensen-Dice coefficient, which is a measure of similarity between two sets. The Dice loss calculates the difference between the predicted segmentation and the ground truth segmentation, with a range of 0 to 1, where 0 indicates no overlap and 1 indicates a perfect overlap. The Dice loss is defined as 1 - (2 * (intersection of predicted and ground truth) / (size of predicted + size of ground truth)). Lower values of the Dice loss indicate a better match between the predicted and ground truth segmentations.\n",
        "\n",
        "Bellow you will found an implementation of it :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The Dice loss function we will use in the model.compile\n",
        "def dice_loss(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then compile it..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\"> Compile model3 with the following parameters : </span>\n",
        " - An Adam optimizer with a learning rate at 0.01\n",
        " - The Dice loss created above\n",
        " - Several metrics :\n",
        "   - Binary Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from metrics_and_losses import recall_m, precision_m, f1_m\n",
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "metrics = [______, ______, ______, ______]\n",
        "\n",
        "______.compile(optimizer = ______, metrics = ______, loss = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will train the model3 for 4 epochs with \"train_ds\" dataset for trainong and \"val_ds\" for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caupMupdfDxU",
        "outputId": "8d3e90cd-fded-44fb-e46e-bf3c86265f56"
      },
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "history = model3.fit(______, epochs = ______, validation_data = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We will see that the f1_score is better with the Dice loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model3 with the test_ds dataset >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "model3_score = ______.evaluate(______)\n",
        "\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "# Display model1 scores\n",
        "print_score(model3_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "# Diplay Tri-bands, mask and prediction of the model3\n",
        "display_sample_prediction(______, ______, ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">What do you think of the Predictions compared to the Masks ?</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can check again the Confusion Matrix >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import display_confusion_matrix, load_masks\n",
        "\n",
        "# test_gt_masks = load_masks(mask_img_paths_test) # already load\n",
        "\n",
        "display_confusion_matrix(predict(model3, test_ds), test_gt_masks)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's try a combination of weighted loss and dice loss."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kD9QgU1ueqHJ"
      },
      "source": [
        "# 4.1 Create and train the 4th model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJId_sdsess9",
        "outputId": "2c553584-7e21-4a3c-fa89-0cb6a3ef691b"
      },
      "outputs": [],
      "source": [
        "model4 = clone_model(model)\n",
        "\n",
        "model4.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a loss which combine a weighted binary crossentropy loss and a dice loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_binary_crossentropy_and_dice(y_true, y_pred):\n",
        "    return weighted_binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\"> Compile model4 with the following parameters : </span>\n",
        " - An Adam optimizer with a learning rate at 0.01\n",
        " - The loss combination of weighted binary crossentropy and dice loss created above\n",
        " - Several metrics :\n",
        "   - Binary Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "metrics = [______, ______, ______, ______]\n",
        "\n",
        "______.compile(optimizer = ______, metrics = ______, loss = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will train the model4 for 4 epochs with \"train_ds\" dataset for trainong and \"val_ds\" for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caupMupdfDxU",
        "outputId": "8d3e90cd-fded-44fb-e46e-bf3c86265f56"
      },
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "history = model4.fit(______, epochs = ______, validation_data = ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model4 with the test_ds dataset >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "model4_score = ______.evaluate(______)\n",
        "\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "# Display model1 scores\n",
        "print_score(model4_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And display some prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "# Diplay Tri-bands, mask and prediction of the model4\n",
        "display_sample_prediction(______, ______, ______)\n",
        "\n",
        "######################################\n",
        "######################################"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:red\">What do you think of the Predictions compared to the Masks ?</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Put your answer bellow** : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can check again the Confusion Matrix >>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import display_confusion_matrix, load_masks\n",
        "\n",
        "# test_gt_masks = load_masks(mask_img_paths_test) # already load\n",
        "\n",
        "display_confusion_matrix(predict(model4, test_ds), test_gt_masks)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5.1 Compare all runs !"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write a code to compare each scores of each runs using print_score(modelX_score) :\n",
        "\n",
        "Don't forget to re-evaluate model1 with recall_m, precision_m, f1_m metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################################\n",
        "# Complete the folowing code replacing \"______\" : \n",
        "######################################\n",
        "\n",
        "metrics = [______, ______, ______, ______]\n",
        "\n",
        "______.compile(metrics = ______)\n",
        "model1_score = ______.evaluate(______)\n",
        "\n",
        "\n",
        "print(\"\\n model1_score :\")\n",
        "print_score(model1_score)\n",
        "print(\"\\n model2 weighted loss :\")\n",
        "print_score(model2_score)\n",
        "print(\"\\n model3 Dice_loss :\")\n",
        "print_score(model3_score)\n",
        "print(\"\\n model4 weighted loss + Dice_loss :\")\n",
        "print_score(model4_score)\n",
        "\n",
        "######################################\n",
        "######################################\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#6. Bonus\n",
        "\n",
        "Go to the Bonus_wildfire.ipynb Notebook.\n",
        "If you have time left, try finding the best combination of loss/weight/epochs/architecture to get a test f1_score higher than 98%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "f24e63ee82b3faf295a1597391f06534fd675e5ceceb862d046bbe914429454a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
